    using System;
    using System.Net.Http;
    using System.Text;
    using System.Threading.Tasks;
    using UnityEngine;

    namespace UniversalText.Core
    {
        /// <summary>
        /// Handles communication with the self-hosted Llama 3 instance via Ollama
        /// </summary>
        public class Llama3Client
        {
            private readonly string _baseUrl;
            private readonly string _modelName;

            private readonly string _defaultPrompt = "Below, in quotation marks, is a text description of a user’s interactions and environment inside of a virtual reality application (such as a VR game or interactive application). The text description is generated by iterating through objects that either the user is directly interacting with in some way, or that are potentially relevant to the context the user is acting within. You are going to respond with a modified version of this description, correcting any parts that sound unnatural and removing any parts of the description that are likely irrelevant. This modified description should describe what the user is doing as concisely as possible, as if it were provided by someone watching their interactions within the VR application from a computer screen, except the information is interpreted as best as possible using the rudimentary description provided below. Do not prepend or append this description with anything, provide the description and the description alone, as your entire response to this prompt will be displayed as if it were the description itself.";

            // Constructor: Initializes the base URL for the Llama 3 instance
            public Llama3Client(string baseUrl, string modelName = "llama3")
            {
                _baseUrl = baseUrl;
                _modelName = modelName;
            }

            /// <summary>
            /// Sends the raw RTR to Llama 3 and retrieves the enhanced version
            /// </summary>
            public async Task<string> GetEnhancedDescriptionAsync(string rawRtr)
            {
                using (HttpClient client = new HttpClient())
                {
                    try
                    {
                        // Create Ollama-compatible request
                        var requestData = new OllamaRequest
                        {
                            model = _modelName,
                            prompt = $"{_defaultPrompt}\n'{rawRtr}'",
                            stream = false
                        };

                        // Convert the request data to JSON
                        string json = JsonUtility.ToJson(requestData);
                        StringContent content = new StringContent(json, Encoding.UTF8, "application/json");

                        Debug.Log($"Sending request to Ollama at {_baseUrl}/api/generate");
                        
                        // Send POST request to Ollama endpoint
                        HttpResponseMessage response = await client.PostAsync($"{_baseUrl}/api/generate", content);
                        
                        if (response.IsSuccessStatusCode)
                        {
                            // Parse the Ollama response
                            string responseBody = await response.Content.ReadAsStringAsync();
                            Debug.Log($"Received response from Ollama: {responseBody}");
                            
                            OllamaResponse responseData = JsonUtility.FromJson<OllamaResponse>(responseBody);
                            return responseData.response;
                        }
                        else
                        {
                            Debug.LogError($"Llama 3 request failed: {response.StatusCode}");
                            return rawRtr;  // Return raw RTR if Llama 3 fails
                        }
                    }
                    catch (Exception ex)
                    {
                        Debug.LogError($"Exception in Llama 3 client: {ex.Message}");
                        return rawRtr;  // Return raw RTR on exception
                    }
                }
            }
        }

        // Helper classes for Ollama API serialization
        [Serializable]
        public class OllamaRequest
        {
            public string model;
            public string prompt;
            public bool stream;
        }

        [Serializable]
        public class OllamaResponse
        {
            public string model;
            public string response;
        }
    }   